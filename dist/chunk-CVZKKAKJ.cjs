'use strict';

var chunk57AVKP4H_cjs = require('./chunk-57AVKP4H.cjs');
var reactHooksAsync = require('@chengsokdara/react-hooks-async');
var react = require('react');

var ae={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0},oe={stop:void 0},ie={blob:void 0,text:void 0},pe=D=>{let{apiKey:m,autoStart:A,autoTranscribe:M,mode:b,nonStop:U,removeSilence:q,stopTimeout:K,streaming:y,timeSlice:O,whisperConfig:u,onDataAvailable:I,onTranscribe:h}={...ae,...D};if(!m&&!h)throw new Error("apiKey is required if onTranscribe is not provided");let f=react.useRef([]),s=react.useRef(),c=react.useRef(),r=react.useRef(),i=react.useRef(),d=react.useRef(oe),[$,S]=react.useState(!1),[j,C]=react.useState(!1),[z,l]=react.useState(!1),[L,T]=react.useState(ie);react.useEffect(()=>()=>{f.current&&(f.current=[]),s.current&&(s.current.flush(),s.current=void 0),r.current&&(r.current.destroy(),r.current=void 0),g("stop"),c.current&&(c.current.off("speaking",k),c.current.off("stopped_speaking",R)),i.current&&(i.current.getTracks().forEach(e=>e.stop()),i.current=void 0);},[]),reactHooksAsync.useEffectAsync(async()=>{A&&await W();},[A]);let N=async()=>{await W();},G=async()=>{await V();},J=async()=>await x(),W=async()=>{try{if(i.current||await Q(),i.current){if(!r.current){let{default:{RecordRTCPromisesHandler:t,StereoAudioRecorder:n}}=await import('recordrtc'),o={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:n,sampleRate:44100,timeSlice:y?O:void 0,type:"audio",ondataavailable:M&&y?Z:void 0};r.current=new t(i.current,o);}if(!s.current){let{Mp3Encoder:t}=await import('lamejs');s.current=new t(1,44100,96);}let e=await r.current.getState();(e==="inactive"||e==="stopped")&&await r.current.startRecording(),e==="paused"&&await r.current.resumeRecording(),U&&B("stop"),S(!0);}}catch{}},Q=async()=>{try{if(i.current&&i.current.getTracks().forEach(e=>e.stop()),i.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!c.current){let{default:e}=await import('hark');c.current=e(i.current,{interval:50,play:!1,threshold:-70}),c.current.on("speaking",k),c.current.on("stopped_speaking",R);}}catch{}},B=e=>{d.current[e]||(d.current[e]=setTimeout(x,K));},k=()=>{C(!0),g("stop");},R=()=>{C(!1),U&&B("stop");},V=async()=>{try{r.current&&(await r.current.getState()==="recording"&&await r.current.pauseRecording(),g("stop"),S(!1));}catch{}},x=async()=>{try{if(r.current){let e=await r.current.getState();(e==="recording"||e==="paused")&&await r.current.stopRecording(),X(),g("stop"),S(!1);let t=await Y();return await r.current.destroy(),f.current=[],s.current&&(s.current.flush(),s.current=void 0),r.current=void 0,t}return null}catch{return null}},X=()=>{c.current&&(c.current.off("speaking",k),c.current.off("stopped_speaking",R),c.current=void 0),i.current&&(i.current.getTracks().forEach(e=>e.stop()),i.current=void 0);},g=e=>{d.current[e]&&(clearTimeout(d.current[e]),d.current[e]=void 0);},Y=async()=>{try{let e="Some default text";if(s.current&&r.current&&await r.current.getState()==="stopped"){l(!0);let n=await r.current.getBlob();if(q){let{createFFmpeg:o}=await import('@ffmpeg/ffmpeg'),a=o({mainName:"main",corePath:chunk57AVKP4H_cjs.b,log:!0});a.isLoaded()||await a.load();let v=await n.arrayBuffer();a.FS("writeFile","in.wav",new Uint8Array(v)),await a.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",chunk57AVKP4H_cjs.c,"out.mp3");let E=a.FS("readFile","out.mp3");if(E.length<=225)return a.exit(),T({blob:n}),l(!1),null;n=new Blob([E.buffer],{type:"audio/mpeg"}),a.exit();}else {let o=await n.arrayBuffer(),a=s.current.encodeBuffer(new Int16Array(o));n=new Blob([a],{type:"audio/mpeg"});}if(typeof h=="function"){let o=await h(n);return T(o),l(!1),o.text??null}l(!1);}return e}catch{return l(!1),null}},Z=async e=>{try{if(y&&r.current){if(I?.(e),s.current){let n=await e.arrayBuffer(),o=s.current.encodeBuffer(new Int16Array(n)),a=new Blob([o],{type:"audio/mpeg"});f.current.push(a);}if(await r.current.getState()==="recording"){let n=new Blob(f.current,{type:"audio/mpeg"}),o=new File([n],"speech.mp3",{type:"audio/mpeg"}),a=await ee(o);a&&T(v=>({...v,text:a}));}}}catch{}},ee=reactHooksAsync.useMemoAsync(async e=>{let t=new FormData;t.append("file",e),t.append("model","whisper-1"),b==="transcriptions"&&u?.language&&t.append("language",u.language),u?.prompt&&t.append("prompt",u.prompt),u?.response_format&&t.append("response_format",u.response_format),u?.temperature&&t.append("temperature",`${u.temperature}`);let n={};n["Content-Type"]="multipart/form-data",m&&(n.Authorization=`Bearer ${m}`);let{default:o}=await import('axios');return (await o.post(chunk57AVKP4H_cjs.d+b,t,{headers:n})).data.text},[m,b,u]);return {recording:$,speaking:j,transcribing:z,transcript:L,pauseRecording:G,startRecording:N,stopRecording:J}};

exports.a = pe;

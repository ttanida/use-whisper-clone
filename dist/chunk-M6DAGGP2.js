import { b, c, d } from './chunk-VO7VPLVP.js';
import { useEffectAsync, useMemoAsync } from '@chengsokdara/react-hooks-async';
import { useRef, useState, useEffect } from 'react';

var ae={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0},ie={stop:void 0},P={blob:void 0,text:void 0},fe=M=>{let{apiKey:b$1,autoStart:A,autoTranscribe:C,mode:T,nonStop:U,removeSilence:q,stopTimeout:K,streaming:S,timeSlice:O,whisperConfig:u,onDataAvailable:I,onTranscribe:d$1}={...ae,...M};if(!b$1&&!d$1)throw new Error("apiKey is required if onTranscribe is not provided");let p=useRef([]),i=useRef(),s=useRef(),r=useRef(),a=useRef(),l=useRef(ie),[$,k]=useState(!1),[j,B]=useState(!1),[z,w]=useState(!1),[N,m]=useState(P);useEffect(()=>()=>{p.current&&(p.current=[]),i.current&&(i.current.flush(),i.current=void 0),r.current&&(r.current.destroy(),r.current=void 0),y("stop"),s.current&&(s.current.off("speaking",R),s.current.off("stopped_speaking",v)),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},[]),useEffectAsync(async()=>{A&&await W();},[A]);let G=async()=>{await W();},J=async()=>{await Y();},Q=async()=>{await E();},V=async()=>await F()||"",W=async()=>{try{if(a.current||await X(),a.current){if(!r.current){let{default:{RecordRTCPromisesHandler:t,StereoAudioRecorder:o}}=await import('recordrtc'),n={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:o,sampleRate:44100,timeSlice:S?O:void 0,type:"audio",ondataavailable:C&&S?ee:void 0};r.current=new t(a.current,n);}if(!i.current){let{Mp3Encoder:t}=await import('lamejs');i.current=new t(1,44100,96);}let e=await r.current.getState();(e==="inactive"||e==="stopped")&&await r.current.startRecording(),e==="paused"&&await r.current.resumeRecording(),U&&x("stop"),k(!0);}}catch{}},X=async()=>{try{if(a.current&&a.current.getTracks().forEach(e=>e.stop()),a.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!s.current){let{default:e}=await import('hark');s.current=e(a.current,{interval:100,play:!1}),s.current.on("speaking",R),s.current.on("stopped_speaking",v);}}catch{}},x=e=>{l.current[e]||(l.current[e]=setTimeout(E,K));},R=()=>{B(!0),y("stop");},v=()=>{B(!1),U&&x("stop");},Y=async()=>{try{r.current&&(await r.current.getState()==="recording"&&await r.current.pauseRecording(),y("stop"),k(!1));}catch{}},E=async()=>{try{if(r.current){let e=await r.current.getState();if((e==="recording"||e==="paused")&&await r.current.stopRecording(),Z(),y("stop"),k(!1),C)await F();else {let t=await r.current.getBlob();m({blob:t});}await r.current.destroy(),p.current=[],i.current&&(i.current.flush(),i.current=void 0),r.current=void 0;}}catch{}},Z=()=>{s.current&&(s.current.off("speaking",R),s.current.off("stopped_speaking",v),s.current=void 0),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},y=e=>{l.current[e]&&(clearTimeout(l.current[e]),l.current[e]=void 0);},F=async()=>{try{if(i.current&&r.current){w(!0);let e=await r.current.getBlob(),t="";if(q){let{createFFmpeg:o}=await import('@ffmpeg/ffmpeg'),n=o({mainName:"main",corePath:b,log:!0});n.isLoaded()||await n.load();let c$1=await e.arrayBuffer();n.FS("writeFile","in.wav",new Uint8Array(c$1)),await n.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",c,"out.mp3");let g=n.FS("readFile","out.mp3");if(g.length<=225)return n.exit(),m({blob:e}),w(!1),"There was an error 1";e=new Blob([g.buffer],{type:"audio/mpeg"}),n.exit();}else {let o=await e.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o));e=new Blob([n],{type:"audio/mpeg"});}if(typeof d$1=="function"){let o=await d$1(e);m(o),t=o.text||"",t="There was an error 4";}return w(!1),t}return "There was an error 2"}catch(e){return w(!1),e instanceof Error?e.message:"An unknown error occurred"}},ee=async e=>{try{if(S&&r.current){if(I?.(e),i.current){let o=await e.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o)),c=new Blob([n],{type:"audio/mpeg"});p.current.push(c);}if(await r.current.getState()==="recording"){let o=new Blob(p.current,{type:"audio/mpeg"}),n=new File([o],"speech.mp3",{type:"audio/mpeg"}),c="";typeof d$1=="function"?c=(await d$1(n)).text||"":c=await re(n),c&&m(g=>({...g,text:c}));}}}catch{}},re=useMemoAsync(async e=>{let t=new FormData;t.append("file",e),t.append("model","whisper-1"),T==="transcriptions"&&t.append("language",u?.language??"en"),u?.prompt&&t.append("prompt",u.prompt),u?.response_format&&t.append("response_format",u.response_format),u?.temperature&&t.append("temperature",`${u.temperature}`);let o={};o["Content-Type"]="multipart/form-data",b$1&&(o.Authorization=`Bearer ${b$1}`);let{default:n}=await import('axios');return (await n.post(d+T,t,{headers:o})).data.text},[b$1,T,u]);return {recording:$,speaking:j,transcribing:z,transcript:N,pauseRecording:J,startRecording:G,stopRecording:Q,setTranscript:m,defaultTranscript:P,clearChunks:()=>{p.current=[];},transcribe:V}};

export { fe as a };
